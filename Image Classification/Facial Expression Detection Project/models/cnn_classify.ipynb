{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `image_dataset_from_directory` Function and its usage \n",
    " `image_dataset_from_directory`is a powerful function that can convert a whole folder of images into a dataset by using just some tweaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7674 files belonging to 2 classes.\n",
      "Using 6140 files for training.\n",
      "Found 7674 files belonging to 2 classes.\n",
      "Using 1534 files for validation.\n",
      "Class Names: ['Happy', 'Sad']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Define dataset directory\n",
    "dataset_dir=\"E:\\Facial_Expression_Dataset\"\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,  # 20% for validation/test\n",
    "    subset=\"training\",\n",
    "    seed=123, \n",
    "    image_size=(150, 150),  \n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(150, 150),\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(\"Class Names:\", class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-`dataset_dir`: Path to the main folder containing class subfolders (e.g., cats, dogs).\n",
    "\n",
    "-`validation_split`=0.2: Reserves 20% of the data for validation.\n",
    "\n",
    "-`subset`=\"training\": Specifies that this dataset is the training part of the split.\n",
    "\n",
    "-`seed`=123: Sets a fixed seed to ensure the split is consistent on each run.\n",
    "\n",
    "-`image_size`=(150, 150): Resizes all input images to 150x150 pixels.\n",
    "\n",
    "-`labels`=\"inferred\": Automatically assigns labels based on folder names.\n",
    "\n",
    "-`label_mode`=\"int\": Returns labels as integers like 0, 1, 2 (not one-hot encoded). Other options for label mode: \"categorical\",\"binary\"\n",
    "\n",
    "-`batch_size`=32: Loads 32 images at a time during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize image for scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image,label):\n",
    "    image=tf.cast(image/255,tf.float32)\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=train_ds.map(normalize)\n",
    "val_ds=val_ds.map(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a very LeNet-5 Architecture for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),  # Ensure this matches\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # Use this for integer labels\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 383ms/step - accuracy: 0.5711 - loss: 0.7214 - val_accuracy: 0.7986 - val_loss: 0.4439\n",
      "Epoch 2/7\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 365ms/step - accuracy: 0.8127 - loss: 0.4226 - val_accuracy: 0.8364 - val_loss: 0.3904\n",
      "Epoch 3/7\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 767ms/step - accuracy: 0.8619 - loss: 0.3238 - val_accuracy: 0.8735 - val_loss: 0.3176\n",
      "Epoch 4/7\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 789ms/step - accuracy: 0.8940 - loss: 0.2582 - val_accuracy: 0.8827 - val_loss: 0.2972\n",
      "Epoch 5/7\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 765ms/step - accuracy: 0.9167 - loss: 0.2021 - val_accuracy: 0.8872 - val_loss: 0.3105\n",
      "Epoch 6/7\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 889ms/step - accuracy: 0.9340 - loss: 0.1683 - val_accuracy: 0.8787 - val_loss: 0.3323\n",
      "Epoch 7/7\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 671ms/step - accuracy: 0.9486 - loss: 0.1361 - val_accuracy: 0.8937 - val_loss: 0.3292\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_ds,epochs=7,validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the entire model (architecture + weights + optimizer state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save(\"model.keras\")  # Save it as an HDF5 file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's test our model for a demo image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the preprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_names = train_ds.class_names # [\"Happy\", \"Sad\"]\n",
    "\n",
    "# Step 1: Load the saved model\n",
    "model=tf.keras.models.load_model('E:\\Machine Learning\\Image Classification\\Facial Expression Detection Project\\models\\model.keras')\n",
    "\n",
    "# Step 2: Preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(150, 150))\n",
    "    \n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  \n",
    "    img_array = img_array / 255.0 # Normalize the image to [0, 1]\n",
    "    \n",
    "    return img_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on demo image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r\"E:\\Machine Learning\\Image Classification\\image.png\"\n",
    "\n",
    "preprocessed_image = preprocess_image(image_path)\n",
    "\n",
    "predictions = model.predict(preprocessed_image)\n",
    "\n",
    "# Get the index of the predicted class (class with the highest probability)\n",
    "predicted_class_index = np.argmax(predictions, axis=1)\n",
    "# Map the index to the actual class name\n",
    "predicted_class = class_names[predicted_class_index[0]]\n",
    "print(f\"Predicted Class: {predicted_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
